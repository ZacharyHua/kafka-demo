
server:
  servlet:
    context-path: /
  port: 8080

spring:
    application:
      name: kafka-demo

  # 数据库

  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    url: jdbc:mysql://47.111.175.146:3306/test_db?useUnicode=true&zeroDateTimeBehavior=convertToNull&allowMultiQueries=true&characterEncoding=UTF-8
    driver-class-name: com.mysql.jdbc.Driver
    username: root
    password: Zhu123456*
  # kafka
  kafka:
    # 指定 kafka 地址可以多个
    bootstrap-servers:
      - 47.111.175.146:9092
#      - 192.168.100.249:9093
#      - 192.168.100.249:9094
    # 指定listener 容器中的线程数，用于提高并发量
    listener:
      batch-listener: true  # 是否开启批量消费，true表示批量消费
      concurrencys: 3,6     # 设置消费的线程数
      poll-timeout: 1500    # 只限自动提交

    # 生产者的配置，大部分我们可以使用默认的，这里列出几个比较重要的属性
    producer:
      # 每次批量发送消息的数量
      batch-size: 1000
      # 设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
      retries: 1
      # producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，producer会阻塞或者抛出异常，以“block.on.buffer.full”来表明。这项设置将和producer能够使用的总内存相关，但并不是一个硬性的限制，因为不是producer使用的所有内存都是用于缓存。一些额外的内存会用于压缩（如果引入压缩机制），同样还有一些用于维护请求。
      buffer-memory: 33554432
      linger: 1
      # key,value序列化方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer

    # 消费者的配置
    consumer:
      # 指定默认消费者group id
      group-id: test-group
      # Kafka中没有初始偏移或如果当前偏移在服务器上不再存在时,默认区最新 ，有三个选项 【latest, earliest, none】
      auto-offset-reset: latest
      # 是否开启自动提交
      enable-auto-commit: true
      # 自动提交的时间间隔
      auto-commit-interval: 100
      # 批量消费一次最大拉取的数据量
      max-poll-records: 3100
      #连接超时时间
      session-timeout: 20000
      #手动提交设置与poll的心跳数,如果消息队列中没有消息，等待毫秒后，调用poll()方法。如果队列中有消息，立即消费消息，每次消费的消息的多少可以通过max.poll.records配置。
      max-poll-interval: 15000
      #设置拉取数据的大小,15M
      max-partition-fetch-bytes: 15728640
      # key,value的解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer


    # 指定默认topic id
    template:
      default-topic: test2

logging:
  level:
    root: info




